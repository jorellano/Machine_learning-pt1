{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters and Model Validation\n",
    "\n",
    "In the previous section, we saw the basic recipe for applying a supervised machine learning model:\n",
    "\n",
    "1. Choose a class of model\n",
    "2. Choose model hyperparameters\n",
    "3. Fit the model to the training data\n",
    "4. Use the model to predict labels for new data\n",
    "\n",
    "The first two pieces of this—the choice of model and choice of hyperparameters—are perhaps the most important part of using these tools and techniques effectively. In order to make an informed choice, we need a way to validate that our model and our hyperparameters are a good fit to the data. While this may sound simple, there are some pitfalls that you must avoid to do this effectively.\n",
    "\n",
    "## Thinking about Model Validation\n",
    "In principle, model validation is very simple: after choosing a model and its hyperparameters, we can estimate how effective it is by applying it to some of the training data and comparing the prediction to the known value.\n",
    "\n",
    "The following sections first show a naive approach to model validation and why it fails, before exploring the use of holdout sets and cross-validation for more robust model evaluation.\n",
    "\n",
    "### Model validation the wrong way\n",
    "Let's demonstrate the naive approach to validation using the Iris data, which we saw in the previous section. We will start by loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"http://my_site.com/my_picture.jpg\")\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we choose a model and hyperparameters. Here we'll use a k-neighbors classifier with n_neighbors=1. This is a very simple and intuitive model that says \"the label of an unknown point is the same as the label of its closest training point:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "model = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we train the mdoel, and use it to predict labels for data we already know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "y_model = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finall,y we compute the fraction of correctly labeled points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see an accuracy score of 1.0, which indicates that 100% of points were correctly labeled by our model! But is this truly measuring the expected accuracy? Have we really come upon a model that we expect to be correct 100% of the time?\n",
    "\n",
    "As you may have gathered, the answer is no. In fact, this approach contains a fundamental flaw: it trains and evaluates the model on the same data. Furthermore, the nearest neighbor model is an instance-based estimator that simply stores the training data, and predicts labels by comparing new data to these stored points: except in contrived cases, it will get 100% accuracy every time!\n",
    "\n",
    "## Model validation the right way: Holdout sets\n",
    "So what can be done? A better sense of a model's performance can be found using what's known as a holdout set: that is, we hold back some subset of the data from the training of the model, and then use this holdout set to check the model performance. This splitting can be done using the train_test_split utility in Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90666666666666662"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "# split the data with 50% in each set\n",
    "X1, X2, y1, y2 = train_test_split(X, y, random_state=0, \n",
    "                                  train_size=0.5)\n",
    "\n",
    "# fit the model on one set of data\n",
    "model.fit(X1, y1)\n",
    "\n",
    "# evaluate the model on the second set of data\n",
    "y2_model = model.predict(X2)\n",
    "accuracy_score(y2, y2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here a more reasonable result: the nearest-neighbor classifier is about 90% accurate on this hold-out set. The hold-out set is similar to unknown data, because the model has not \"seen\" it before.\n",
    "\n",
    "## Model validation via cross-validation\n",
    "One disadvantage of using a holdout set for model validation is that we have lost a portion of our data to the model training. In the above case, half the dataset does not contribute to the training of the model! This is not optimal, and can cause problems – especially if the initial set of training data is small.\n",
    "\n",
    "One way to address this is to use cross-validation; that is, to do a sequence of fits where each subset of the data is used both as a training set and as a validation set. Visually, it might look something like this:\n",
    "\n",
    "1. Choose aq class of model\n",
    "2. Choose model hyperparameters \n",
    "3. Fit the model to the training data\n",
    "4. Use the mdoiel to precit labels for new data\n",
    "\n",
    "        The first two pieces of this- the choise of model and choice of hyperparameters- are perfaps the modst importtant part of using these tools and techniques effectively. In order to make an informed choice, we need a way to validate, that our model and our hyperparameters are a good fit to the data. While this may sound simple, ther are some piutfalls that you must avoide to do this effectively.\n",
    "        \n",
    "## Thinking about Model Validation\n",
    "\n",
    "In principle, model validation is very simple: after choosing a model and its hyperparameters, we can estimate how effective it is by applying it to some of the training data and comparing the prediction to the known value.\n",
    "\n",
    "The following sections first show a naive approach to model validation and why it falls, before exploring the use of holdout sets and cross-validation for more robust model evaluation.\n",
    "\n",
    "## Model validation the wrong way\n",
    "\n",
    "Let's demonstrate the naive approach to validation using the training data, which we saw in the previous section. We will start byt loading the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next we choose a model and hyperparameters. Here we'll use a k-neighbors classifier with n_neighbors=1. This is a very simple and intuitive model that says \"the label of an unknown point is the same as the label of its closes training point\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Then we train the model, and use it to predict labels for data we already know:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "y_model = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Finally, we compoute the fraction of correctly labeled points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see an accuracy score of 1.0, which indicates that 100% of points were correctly labeled by our model! But this is truly measuring the expected accuracy? Have we really come upon a model that we expect to be correct 100% of the time?\n",
    "\n",
    "As you may have gathered, the answer is no. In fact, this approach contaions a fundamental flaw: *it trains and evaluates the model on the same data*. Futhermore, the nearest neighbor model is an instance-based estimator that simply stores the training data, and predicts labels by comparing new data to these stored points: except in contrived cases, it will get 100% accuracy everyt time!\n",
    "\n",
    "## Model validation the right way: Holdout sets\n",
    "\n",
    "So what can be done? A better sense of a model's performance can be found using what's known as a holdout set: that is, we hold back some subset of the data from the training of the mode, and then use this holout set to check the model performance. This splitting can be done using the *train_set_split* function in Sci-kitlearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90666666666666662"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "#load iris data\n",
    "iris = load_iris()\n",
    "\n",
    "# give a value to each value of the iris dataset\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "#choose the model of hyper parameters (KN) \n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# train model, and use it to predict labels for data we know.\n",
    "model.fit(X, y)\n",
    "y_model = model.predict(X)\n",
    "\n",
    "#compute the fraction of correctly labeled points\n",
    "accuracy_score(y, y_model)\n",
    "\n",
    "# Split the data with 50% in each set\n",
    "\n",
    "X1, X2, y1, y2 = train_test_split(X, y, random_state=0,\n",
    "                                  train_size=0.5)\n",
    "\n",
    "# fit the model on one set of data\n",
    "model.fit(X1, y1)\n",
    "\n",
    "# evaluate the model on the second set of data\n",
    "\n",
    "y2_model = model.predict(X2)\n",
    "accuracy_score(y2, y2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see here a more reasonable result: the nearest-neighbor classifier is about 90% accurate on this hold-out set. The hold-out set is similar to unknown data, because the model has not \"seen\" it before.\n",
    "\n",
    "## Model Validation via cross-validation\n",
    "\n",
    "One disadvantage of using a holdout set for model validation is that we have lost a poriton of our data to the model training. \n",
    "In the above case, half the dataset does not contribute to the training of the model! This is not optimal, and can cause problems – especially if the initial set of training data is small.\n",
    "\n",
    "One way to address this is to use cross-validation; that is, to do a sequence of fits where each subset of the data is used both as a training set and as a validation set. Visually, it might look something like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.95999999999999996, 0.90666666666666662)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we do two validation trials, alternately using each half of the data as a holdoutset. Using the split data from before,\n",
    "# we could implment it like this:\n",
    "\n",
    "y2_model = model.fit(X1, y1).predict(X2)\n",
    "y1_model = model.fit(X2, y2).predict(X1)\n",
    "accuracy_score(y1, y1_model), accuracy_score(y2, y2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What comes out are two accuracy scores, which we could combine (by, say, taking the mean)two-fold cross-validation—that is, one in which we have split the data into two sets and used each in turn as a validation set.\n",
    "\n",
    "We could expand on this idea to use even more trials, and more folds in the data—for example, here is a visual depiction of five-fold cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.03-5-fold-CV.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.03-5-fold-CV.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here we split the data into five groups, and use each of them in turn to evaluate the model fit on the other 4/5 of the data. This would be rather tedious to do by hand, and so we can use Scikit-Learn's cross_val_score convenience routine to do it succinctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96666667,  0.96666667,  0.93333333,  0.93333333,  1.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Repeating the validation across different subsets of the data gives us an even better idea of the performance of the algorithm.\n",
    "\n",
    "Scikit-Learn implements a number of useful cross-validation schemes that are useful in particular situations; these are implemented via iterators in the cross_validation module. For example, we might wish to go to the extreme case in which our number of folds is equal to the number of data points: that is, we train on all points but one in each trial. This type of cross-validation is known as leave-one-out cross validation, and can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import LeaveOneOut\n",
    "scores = cross_val_score(model, X, y, cv=LeaveOneOut(len(X)))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Because we have 150 samples, the leave one out cross-validation yields scores for 150 trials, and the score indicates either successful (1.0) or unsuccessful (0.0) prediction. Taking the mean of these gives an estimate of ther error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95999999999999996"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other cross-validation schemes can be used similiarly. For a description of what is available in scikit-learn, use Ipython to explore the sklearn.cross_validation submodule, or take a look at Scikit-learns online cross validation documentation.\n",
    "\n",
    "## Selecting the Best Model \n",
    "Now that we've seen the basics of validation and cross-validation, we will go into a litte more depth regarding model selection and selection of hyperparameters. These issues are some of the most important aspects of the practice of machine learning, and I find that this information is often glossed over in introductory machine learning tutorials.\n",
    "\n",
    "Of core importance is the following question: if our estimator is underperforming, how should we move forward? There are several possible answers:\n",
    "\n",
    "- Use a more complicated/more flexible model\n",
    "- Use a less complicated/less flexible model\n",
    "- Gather more training samples\n",
    "- Gather more data to add features to each sample\n",
    "\n",
    "The answer to this question is often counter-intuitive. In particular, sometimes using a more complicated model will give worse results, and adding more training samples may not improve your results! The ability to determine what steps will improve your model is what separates the successful machine learning practitioners from the unsuccessful.\n",
    "\n",
    "### The Bias-variance trade-off\n",
    "Fundamentally, the question of \"the best model\" is about finding a sweet spot in the tradeoff between bias and variance. Consider the following figure, which presents two regression fits to the same dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.03-bias-variance.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url = \"http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.03-bias-variance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that neither of these models is a particularly good fit to the data, but they fail in different ways.\n",
    "\n",
    "The model on the left attempts to find a straight-line fit through the data. Because the data are intrinsically more complicated than a straight line, the straight-line model will never be able to describe this dataset well. Such a model is said to underfit the data: that is, it does not have enough model flexibility to suitably account for all the features in the data; another way of saying this is that the model has high bias.\n",
    "\n",
    "The model on the right attempts to fit a high-order polynomial through the data. Here the model fit has enough flexibility to nearly perfectly account for the fine features in the data, but even though it very accurately describes the training data, its precise form seems to be more reflective of the particular noise properties of the data rather than the intrinsic properties of whatever process generated that data. Such a model is said to overfit the data: that is, it has so much model flexibility that the model ends up accounting for random errors as well as the underlying data distribution; another way of saying this is that the model has high variance.\n",
    "\n",
    "To look at this in another light, consider what happens if we use these two models to predict the y-value for some new data. In the following diagrams, the red/lighter points indicate data that is omitted from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.03-bias-variance-2.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url = \"http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.03-bias-variance-2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score here is $R^2$ score, or coefficient of determination, which measures how well a model performs relative to a simple mean of the target values. $R^2=1$ indicates a perfect match, $R^2=0$ indicates the model does no better than simply taking the mean of the data, and negative values mean even worse models. From the scores associated with these two models, we can make an observation that holds more generally:\n",
    "\n",
    "- For high-bias models, the performance of the model on the validation set is similar to the performance on the training set.\n",
    "- For high-variance models, the performance of the model on the validation set is far worse than the performance on the training set.\n",
    "\n",
    "If we imagine that we have some ability to tune the model complexity, we would expect the training score and validation score to behave as illustrated in the following figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.03-validation-curve.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url = \"http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.03-validation-curve.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagram shown here is often called a validation curve, and we see the following essential features:\n",
    "\n",
    "- The training score is everywhere higher than the validation score. This is generally the case: the model will be a better fit to data it has seen than to data it has not seen.\n",
    "- For very low model complexity (a high-bias model), the training data is under-fit, which means that the model is a poor predictor both for the training data and for any previously unseen data.\n",
    "- For very high model complexity (a high-variance model), the training data is over-fit, which means that the model predicts the training data very well, but fails for any previously unseen data.\n",
    "- For some intermediate value, the validation curve has a maximum. This level of complexity indicates a suitable trade-off between bias and variance.\n",
    "\n",
    "The means of tuning the model complexity varies from model to model; when we discuss individual models in depth in later sections, we will see how each model allows for such tuning.\n",
    "\n",
    "\n",
    "\n",
    "### Validation curves in Scikit-Learn\n",
    "\n",
    "Let's look at an example of using cross-validation to compute the validation curve for a class of models. Here we will use a polynomial regression model: this is a generalized linear model in which the degree of the polynomial is a tunable parameter. For example, a degree-1 polynomial fits a straight line to the data; for model parameters $a$ and $b$:\n",
    "\n",
    "$y=ax+b$\n",
    "\n",
    "A degree-3 polynomial fits a cubic curve to the data; for model parameters $ a,b,c,d:$\n",
    "\n",
    "$y=ax3+bx2+cx+d$\n",
    "\n",
    "\n",
    "We can generalize this to any number of polynomial features. In Scikit-Learn, we can implement this with a simple linear regression combined with the polynomial preprocessor. We will use a pipeline to string these operations together (we will discuss polynomial features and pipelines more fully in Feature Engineering):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),\n",
    "                        LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now let's create some data to which we will fit our model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def make_data(N, err=1.0, rseed=1):\n",
    "    #randomly sample the data\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    X = rng.rand(N, 1) ** 2\n",
    "    y = 10 - 1. / (X.ravel() +.1)\n",
    "    if err > 0:\n",
    "        y += err * rng.randn(N)\n",
    "        return X, y\n",
    "X, y = make_data(40)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can now visualize our data, a;long with polyno,mials fits of several degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAFVCAYAAAA6zUwUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsKmpQPsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x951a410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set() # plot formatting\n",
    "\n",
    "X_test = np.linspace(-.1, 1.1, 500)[:, None]\n",
    "\n",
    "plt.scatter(X.ravel(), y, color='black')\n",
    "axis = plt.axis()\n",
    "for degree in [1, 3, 5]:\n",
    "    y_test = PolynomialRegression(degree).fit(X, y).predict(X_test)\n",
    "    plt.plot(X_test.ravel(), y_test, label='degree={0}'.format(degree))\n",
    "plt.xlim(-0.1, 1.0)\n",
    "plt.ylim(-2, 12)\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The knob controlling model complexity in this case is the degree of the polynomial, which can be any non-negative integer. A useful question to answer is this: what degree of polynomial provides a suitable trade-off between bias (under-fitting) and variance (over-fitting)?\n",
    "\n",
    "We can make progress in this by visualizing the validation curve for this particular data and model; this can be done straightforwardly using the validation_curve convenience routine provided by Scikit-Learn. Given a model, data, parameter name, and a range to explore, this function will automatically compute both the training score and validation score across the range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
